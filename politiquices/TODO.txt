Web App
=======

    - acabar o relatório
    - fazer o script para o video
        - roadmap da apresentação
            1. intro_ explicar o que é o projecto
                - tirar frases chave do relatório
            2. mostrar um exemplo com queries
            3. mostrar um exemplo de navegação no grafo

    - arranjar notícias com estes gajos!
        https://www.wikidata.org/wiki/Q52112309
        https://www.wikidata.org/wiki/Q72310730

    - stats apenas com 'oposição' e 'apoio'
    - espaço entre filtro tempo + botão 'PROCURAR'

    - procurar por Mário Centeno, "á" -> autocomplete

    - sparlq queries no index, abrir janela nova? adicionar 'todas' ?

    - verificar todas as possibilidades deste query
        https://www.politiquices.pt/queries?query_nr=one
        $e1=Q21568721&e2=Q610788
        &year_from=2000
        &year_to=2019
        &relationship=apoia -> dará para por todas aqui?
        &html=true
        &annotate



    - BUGS:
        Bugs nos gráficos individuais e tabelas com relações, exemplos:
            - https://www.politiquices.pt/entity?q=Q60780752


        - BE vs. BE - "Helena Pinto subsitui Louça" -> query sparql está a apanhar 'other' ?
            https://www.politiquices.pt/entity?q=Q10294458&annotate


        - http://0.0.0.0:5000/entity?q=Q10395752
            'Álvaro Almeida' != Álvaro Augusto Matos Almeida

    - Grafo:
        - Personalidade box com entradas repetidas
        - limpar, ficar na versão final
        - arrastar um nó e parar, desligar a física
        - triangulos politicos: qual a relação tipica entre X e Y, se X e Y sempre acusam/defendem Z
        - max_hops numa rede
        - https://www.politiquices.pt/entity?q=Q3060511 -> Eurico de Melo
            - 2 relações na tabela, mas apenas 1 no grafo

        - António Vitorino apoia Durão Barroso 2004-2004:
            - mostra 2 no arco, só há 1


    - Checklist
        - Site:
            - Não há 'other' relationships em lado nenhum
            - Apenas mostra pessoas que têm relações
            - Relações são todas "opõe-se" / "apoia"
            - Não há texto nenhum em inglês

        - GitHub:
            - no training data
            - no hard-coded passwords
            - no hard-coded IP addresses


    - Analytics de acessos
        - https://matomo.org/
        - https://computingforgeeks.com/install-matomo-piwik-web-analytics-tool-on-ubuntu/
        - https://www.howtoforge.com/how-to-install-matomo-web-analytics-on-ubuntu-2004/

    - HTML:
        - Limpar o Javascript: re-utilizar
        - libs todas locais
        - CSS todo fora do HTML

    entity_linking
    --------------
        - remover os hard mappings do query_kb? e.g., Costa -> António Costa
            - 'Costa':
                - is not always 'António Costa', can be often 'Carlos Costa' -> https://arquivo.pt/wayback/20141117234314/http://expresso.sapo.pt/marco-costa-discute-saida-da-familia-do-bes-salgado-diz-que-seria-o-diluvio=f898400
                - apply entity linking algorithm


    Geral (low)
    ----------
        - Load on scroll on politiquices.pt tem um erro, repete rows, porque?

        - tirar todos os alerts -> substituir por uma pagina de erro -> ir para index.html

        - party members: - load on scroll down ?
        - clicar no branco fazer collapse ao menu (hamburger)
        - cache + cópia do resize das imagens para este display

        Agregacoes + info na personalidade:
        ------------------------------------
             - Governo
             - Assembleias
             - Profissao
             - Educacao
             - listar todos os membros do Governo X
             - listar todos os que já foram Ministros <qq cena>
             - listar relações familiares

        DevOps:
        -------
            - backup dos certificados HTTPS
            - fix /etc/systemd/system/myproject.service probably needs uwsgi as apt-get instead pip install
            - Wrap everything in docker, it's reproducible ?


relationship classifier
======================
    - run script with PYTHONHASHSEED=0
    - explorar os padroes encontrados
    - controlar overfitting?

    - Transformer models: https://huggingface.co/transformers/quicktour.html

    - Training Neural Networks:
        - ModelCheckpoint: maximize for precision in lowest class
        - Optimizer and Learning Rate
        - batch size, Early Stop
        - https://parameterfree.com/2020/12/06/neural-network-maybe-evolved-to-make-adam-the-best-optimizer/
        - https://spacy.io/usage/training#tips
        - http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines
        - https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21

    - https://towardsdatascience.com/handling-class-imbalanced-data-using-a-loss-specifically-made-for-it-6e58fd65ffab
    - https://www.tensorflow.org/tutorials/structured_data/imbalanced_data
    - https://github.com/vandit15/Class-balanced-loss-pytorch

    - embeddings
        - Uppercase and lower case, improvement?
        - better/cleaner higher dimensions? train on own corpus
        - catch negations, how? e.g.: defende != não + defende
        - tool to visualize embeddings

    🔹 Look at the data carefully. Do EDA
    🔹 Look at the targets. See how they are distributed & what kind of problem this is
    🔹 Choose the right metric to evaluate your models
    🔹 Split the data into folds. You can use this for cross-validation or for hold out based validation
    🔹 Build a first basic model. This is going to be your baseline.
    🔹 Now try to improve on the baseline by adding new features
    🔹 To add new features, go back to data. Look at the EDA. That's why its quite important
    🔹 When you think you have reached a limit with feature engineering, try different models
    🔹 Keep log of all the scores, features and models
    🔹 When you think you have reached a limit with different models, try feature selection
    🔹 Done with feature engineering and feature selection? You will realize that by following above steps, you have also chosen a few best models that work well with your data
    🔹 Now its time to do hyperparameter optimization and squeeze the last few drops from your best models
