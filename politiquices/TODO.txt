Web App
=======
	
	- Perguntas como "Com quem se relaciona mais frequentemente?" tamb√©m d√£o bastante trabalho a processar. Fica mais f√°cil se for "Rela√ß√µes"

	- - Verbo "op√µe-se" n√£o tem uma leitura imediata. Demorei um bocado a perceber o o que era. Se calhar substituia por  "Oposto a". Assim fica "Oposto a", "Oposto por", "Apoia", "Apoiado por".
	
	"oposto a", "oposto por", "apoia", "apoiado por" -> normalizar em todo o lado


    - TODO: encurtar nomes com mais de 2 ou 3 nomes
	- estat√≠sticas: label "mostrar" / "esconder"
    - ao carregar o index.html: limpar as input boxes
    - garantir que quando se sai do grafo por pesquisar por personalidade nao ficam popup boxes
    - erros de param√™tros nao v√°lidos no URL:
        - queries/ tem que ter duas entidades validas
        - fazer redirect para o index.html com mensagem de erro

    - Adicionar o Entity Versus Entity
    - tirar todos os alerts -> substituir por uma pagina de erro -> ir para index.html

    Vi uma estranha..o Donald trump tinha liga√ß√£o ao Miguel poiares maduro, mas depois ao clicar
    na not√≠cia era o maduro da Venezuela üôÇ

    - acabar o relat√≥rio

    - fazer o script para o video

            1. intro_ explicar o que √© o projecto
                - tirar frases chave do relat√≥rio

            2. mostrar os dados de uma personalidade individual

            3. mostrar um exemplo com queries
               2.1 per vs per
               2.2 per vs party
               2.3 part vs. per
               2.4 party vs party

            4. mostrar um exemplo de navega√ß√£o no grafo
               3.1 uma rede geral
               3.2 a rede uma entidade em espec√≠fico

    - espa√ßo entre filtro tempo + bot√£o 'PROCURAR'

    - Quais as personalidades (importantes) na wikidata que n√£o aparecem no politiquices.pt?
        - https://www.wikidata.org/wiki/Q52112309
        - https://www.wikidata.org/wiki/Q72310730

    - JS libs todas locais
        - bootstrap-table javascript local
        - Datatables: final do base.html -> por tudo local

    - Grafo:
        - arrastar um n√≥ e parar, desligar a f√≠sica
        - max_hops numa rede
        - triangulos politicos: qual a rela√ß√£o tipica entre X e Y, se X e Y sempre acusam/defendem Z

    - Analytics de acessos
        - https://matomo.org/
        - https://computingforgeeks.com/install-matomo-piwik-web-analytics-tool-on-ubuntu/
        - https://www.howtoforge.com/how-to-install-matomo-web-analytics-on-ubuntu-2004/

    - HTML:
        - Limpar o Javascript: re-utilizar
        - CSS todo fora do HTML


    entity_linking
    --------------
        - verify if these titles are in 'Ant√≥nio Costa' or 'Carlos Costa'
            - Banif: Centeno desmente Bruxelas e Costa rebate narrativa da "falha grave"
            - Mar√ßo: Costa discute sa√≠da da fam√≠lia do BES. Salgado diz que seria o dil√∫vio

        - '√Ålvaro Almeida' != √Ålvaro Augusto Matos Almeida
            - http://0.0.0.0:5000/entity?q=Q10395752

    Geral (low)
    ----------
        - Load on scroll on politiquices.pt tem um erro, repete rows, porque?
        - party members: - load on scroll down ?
        - clicar no branco fazer collapse ao menu (hamburger)
        - cache + c√≥pia do resize das imagens para este display

        Agregacoes + info na personalidade:
        ------------------------------------
             - Governo
             - Assembleias
             - Profissao
             - Educacao
             - listar todos os membros do Governo X
             - listar todos os que j√° foram Ministros <qq cena>
             - listar rela√ß√µes familiares

        DevOps:
        -------
            - fix /etc/systemd/system/myproject.service probably needs uwsgi as apt-get instead pip install
            - Wrap everything in docker, it's reproducible ?



relationship classifier
======================
    - se o output √© 'other' n√£o faz sentido correr o classificador de direc√ß√£o

    - run script with PYTHONHASHSEED=0
    - explorar os padroes encontrados
    - controlar overfitting?

    - Transformer models: https://huggingface.co/transformers/quicktour.html

    - Training Neural Networks:
        - ModelCheckpoint: maximize for precision in lowest class
        - Optimizer and Learning Rate
        - batch size, Early Stop
        - https://parameterfree.com/2020/12/06/neural-network-maybe-evolved-to-make-adam-the-best-optimizer/
        - https://spacy.io/usage/training#tips
        - http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines
        - https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21

    - https://towardsdatascience.com/handling-class-imbalanced-data-using-a-loss-specifically-made-for-it-6e58fd65ffab
    - https://www.tensorflow.org/tutorials/structured_data/imbalanced_data
    - https://github.com/vandit15/Class-balanced-loss-pytorch

    - embeddings
        - Uppercase and lower case, improvement?
        - better/cleaner higher dimensions? train on own corpus
        - catch negations, how? e.g.: defende != n√£o + defende
        - tool to visualize embeddings

    üîπ Look at the data carefully. Do EDA
    üîπ Look at the targets. See how they are distributed & what kind of problem this is
    üîπ Choose the right metric to evaluate your models
    üîπ Split the data into folds. You can use this for cross-validation or for hold out based validation
    üîπ Build a first basic model. This is going to be your baseline.
    üîπ Now try to improve on the baseline by adding new features
    üîπ To add new features, go back to data. Look at the EDA. That's why its quite important
    üîπ When you think you have reached a limit with feature engineering, try different models
    üîπ Keep log of all the scores, features and models
    üîπ When you think you have reached a limit with different models, try feature selection
    üîπ Done with feature engineering and feature selection? You will realize that by following above steps, you have also chosen a few best models that work well with your data
    üîπ Now its time to do hyperparameter optimization and squeeze the last few drops from your best models
